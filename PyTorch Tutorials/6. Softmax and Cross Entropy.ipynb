{"cells":[{"source":"# Softmax \n![image-4](image-4.png)\n\nIt applies the exponential function to each element and normalizes it by dividing by the sum of all these exponentials. \n\nBasically squishes output to be between 0-1 and help to calculate probability.","metadata":{},"cell_type":"markdown","id":"944bd089-76f7-4900-baf1-1dc57cbb7021"},{"source":"import torch\n\nx = torch.tensor([2.0,1.0,0.1])\noutputs = torch.softmax(x, dim=0) # dimension so that it computes along the first axis\noutputs","metadata":{"executionTime":1175,"lastSuccessfullyExecutedCode":"import torch\n\nx = torch.tensor([2.0,1.0,0.1])\noutputs = torch.softmax(x, dim=0) # dimension so that it computes along the first axis\noutputs"},"cell_type":"code","id":"dbf0a813-7496-49c2-89e1-06314c15f1a7","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"tensor([0.6590, 0.2424, 0.0986])"},"metadata":{}}]},{"source":"# Cross-Entropy\n![image-5](image-5.png)\n\n- Bad prediction = high cross entropy loss \n- Good prediction = low cross entropy loss","metadata":{},"cell_type":"markdown","id":"10d97d09-312a-4cc2-b46d-43d1094df8e8"},{"source":"![image-6](image-6.png)\n","metadata":{},"cell_type":"markdown","id":"30e62bc8-3637-41b3-86bd-90b1966c6efd"},{"source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\n# instatntiate loss\nloss = nn.CrossEntropyLoss()\n\ny =torch.tensor([0])\ny","metadata":{"executionTime":331,"lastSuccessfullyExecutedCode":"import torch\nimport torch.nn as nn\nimport numpy as np\n\n# instatntiate loss\nloss = nn.CrossEntropyLoss()\n\ny =torch.tensor([0])\ny"},"cell_type":"code","id":"5ee44792-d8fe-408a-884e-7baa335658de","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"tensor([0])"},"metadata":{}}]},{"source":"# nsamples x nclasses =1x3 (1 sample in 3 possible classes)\ny_pred_good = torch.tensor([[2.0,1.0,0.1]]) #<-- not applied softmax\ny_pred_bad = torch.tensor([[0.5,2.0,0.3]]) #<-- not applied softmax","metadata":{"executionTime":65,"lastSuccessfullyExecutedCode":"# nsamples x nclasses =1x3 (1 sample in 3 possible classes)\ny_pred_good = torch.tensor([[2.0,1.0,0.1]]) #<-- not applied softmax\ny_pred_bad = torch.tensor([[0.5,2.0,0.3]]) #<-- not applied softmax"},"cell_type":"code","id":"74538fa9-1e33-43fe-8341-0b10ee67bf8d","execution_count":3,"outputs":[]},{"source":"# compute loss\nl1 = loss(y_pred_good, y)\nl2 = loss(y_pred_bad, y)\n\nl1,l2","metadata":{"executionTime":67,"lastSuccessfullyExecutedCode":"# compute loss\nl1 = loss(y_pred_good, y)\nl2 = loss(y_pred_bad, y)\n\nl1,l2"},"cell_type":"code","id":"e3d13052-a460-41a4-8de7-c5e79cb6f337","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(tensor(0.4170), tensor(1.8406))"},"metadata":{}}]},{"source":"Good predicted value has less Cross Entropy Loss than bad predicted value.","metadata":{},"cell_type":"markdown","id":"64d64f18-c01a-4625-8232-d7de7463eb16"},{"source":"# get actual predictions\n_, predictions1 = torch.max(y_pred_good, 1)\n_, predictions2 = torch.max(y_pred_bad, 1)\n\npredictions1, predictions2","metadata":{"executionTime":616,"lastSuccessfullyExecutedCode":"# get actual predictions\n_, predictions1 = torch.max(y_pred_good, 1)\n_, predictions2 = torch.max(y_pred_bad, 1)\n\npredictions1, predictions2"},"cell_type":"code","id":"cd62c19d-a167-413b-83ae-3c6788c4743f","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(tensor([0]), tensor([1]))"},"metadata":{}}]},{"source":"- Good prediction --> correct predicted that sample belongs to class 0\n- Bad prediction --> incorrect prediction","metadata":{},"cell_type":"markdown","id":"789d6c80-ae02-4a4f-9127-c9355541fa3e"},{"source":"### Cross Entropy in multiple samples","metadata":{},"cell_type":"markdown","id":"06a2527f-a171-4a1a-814a-a093cc7cfc59"},{"source":"# suppose 3 samples\ny = torch.tensor([2,0,1])\n\n# nsamples x nclasses =3x3 (3 sample in 3 possible classes)\ny_pred_good = torch.tensor([[0.1,1.0,2.0],[2.0,1.0,0.1],[0.0,3.0,0.1] ])\ny_pred_bad = torch.tensor([[2.5,1.0,0.3],[0.1,1.0,2.1],[0.1,3.0,0.1]])","metadata":{"executionTime":74,"lastSuccessfullyExecutedCode":"# suppose 3 samples\ny = torch.tensor([2,0,1])\n\n# nsamples x nclasses =3x3 (3 sample in 3 possible classes)\ny_pred_good = torch.tensor([[0.1,1.0,2.0],[2.0,1.0,0.1],[0.0,3.0,0.1] ])\ny_pred_bad = torch.tensor([[2.5,1.0,0.3],[0.1,1.0,2.1],[0.1,3.0,0.1]])"},"cell_type":"code","id":"d27c7d26-ef27-42f5-bb0d-3919dbb36828","execution_count":6,"outputs":[]},{"source":"# compute loss\nl1 = loss(y_pred_good, y)\nl2 = loss(y_pred_bad, y)\n\nl1,l2","metadata":{"executionTime":44,"lastSuccessfullyExecutedCode":"# compute loss\nl1 = loss(y_pred_good, y)\nl2 = loss(y_pred_bad, y)\n\nl1,l2"},"cell_type":"code","id":"1144166c-ec5f-412d-a362-923b401d880f","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(tensor(0.3112), tensor(1.6589))"},"metadata":{}}]},{"source":"# get actual predictions\n_, predictions1 = torch.max(y_pred_good, 1)\n_, predictions2 = torch.max(y_pred_bad, 1)\n\npredictions1, predictions2","metadata":{"executionTime":56,"lastSuccessfullyExecutedCode":"# get actual predictions\n_, predictions1 = torch.max(y_pred_good, 1)\n_, predictions2 = torch.max(y_pred_bad, 1)\n\npredictions1, predictions2"},"cell_type":"code","id":"3ee2f164-1982-41c8-8347-ffb217488fa1","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(tensor([2, 0, 1]), tensor([0, 2, 1]))"},"metadata":{}}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}